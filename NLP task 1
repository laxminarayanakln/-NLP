# task 1
import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')

text = "Tokenization without transformers is straightforward with tools like NLTK."

# Tokenization with NLTK
tokens = word_tokenize(text)
print("Tokens:", tokens)

# Transformers tokenization
from transformers import AutoTokenizer

# Load BERT tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Tokenize text and return PyTorch tensors
tokens_transformers = tokenizer(text, return_tensors="pt")
print("Transformers Tokens:", tokens_transformers)

# Convert token IDs to tokens (list of strings)
tokens_transformers_list = tokenizer.convert_ids_to_tokens(tokens_transformers['input_ids'][0].tolist())
print("Transformers Tokens (List):", tokens_transformers_list)

# Decode token IDs back to string (without special tokens)
decoded_text = tokenizer.decode(tokens_transformers['input_ids'][0], skip_special_tokens=True)
print("Decoded Text:", decoded_text)
 
